receivers:
  otlp:
    protocols:
      http:
        endpoint: 0.0.0.0:4318
  filelog/std:
    include: [ /var/log/**log ]
    # start_at: beginning
  hostmetrics:
    root_path: /
    collection_interval: 30s
    scrapers:
      cpu:
      disk:
      filesystem:
      load:
      memory:
      network:
      paging:          
      processes:
      # process: # a bug in the process scraper causes the collector to throw errors so disabling it for now
processors:
  resourcedetection/system:
    detectors: ["system"]
    system:
      hostname_sources: ["os"]
  memory_limiter:
    check_interval: 1s
    limit_percentage: 75
    spike_limit_percentage: 15
  batch:
    send_batch_size: 10000
    timeout: 10s

extensions:
  zpages: {}

exporters:
  otlphttp/openobserve:
    endpoint: https://api.openobserve.ai/api/${env:OPEN_OBSERVE_ORG}
    headers:
      Authorization: "Basic ${env:OPEN_OBSERVE_TOKEN}"
  otlphttp/openobserve_ridi:
    endpoint: https://api.openobserve.ai/api/${env:OPEN_OBSERVE_ORG}
    headers:
      Authorization: "Basic ${env:OPEN_OBSERVE_TOKEN}"
      stream-name: ridi_${env:RIDI_ENV_NAME}

service:
  extensions: [zpages]
  pipelines:
    metrics:
      receivers: [hostmetrics]
      processors: [resourcedetection/system, memory_limiter, batch]
      exporters: [otlphttp/openobserve]
    logs/ridi:
      receivers: [otlp]
      processors: [resourcedetection/system, memory_limiter, batch]
      exporters: [otlphttp/openobserve_ridi]
    logs:
      receivers: [filelog/std]
      processors: [resourcedetection/system, memory_limiter, batch]
      exporters: [otlphttp/openobserve]
